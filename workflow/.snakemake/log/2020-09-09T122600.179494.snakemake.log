Building DAG of jobs...
Using shell: /bin/bash
Provided cores: 1
Rules claiming more threads will be scaled down.
Job counts:
	count	jobs
	1	all
	1	mark_duplicates
	2

[Wed Sep  9 12:26:00 2020]
rule mark_duplicates:
    input: results/sorted/BRCA_NA12892.sorted.bam
    output: results/dedup/BRCA_NA12892.dedup.bam, results/dedup/BRCA_NA12892.markdup.metrics.txt
    log: logs/picard/dedup/BRCA_NA12892.log
    jobid: 1
    wildcards: sample=BRCA_NA12892

[Wed Sep  9 12:26:12 2020]
Error in rule mark_duplicates:
    jobid: 1
    output: results/dedup/BRCA_NA12892.dedup.bam, results/dedup/BRCA_NA12892.markdup.metrics.txt
    log: logs/picard/dedup/BRCA_NA12892.log

RuleException:
CalledProcessError in line 82 of /tier4/DSC/GATK/ehlim/gatk_germline_pipeline/workflow/rules/mapping.smk:
Command ' set -euo pipefail;  gatk MarkDuplicates -I results/sorted/BRCA_NA12892.sorted.bam -O results/dedup/BRCA_NA12892.dedup.bam -M results/dedup/BRCA_NA12892.markdup.metrics.txt 2> logs/picard/dedup/BRCA_NA12892.log ' returned non-zero exit status 3.
  File "/tier4/DSC/GATK/ehlim/gatk_germline_pipeline/workflow/rules/mapping.smk", line 82, in __rule_mark_duplicates
  File "/home/ehlim/tools/miniconda3/envs/gatk/lib/python3.6/concurrent/futures/thread.py", line 56, in run
Shutting down, this might take some time.
Exiting because a job execution failed. Look above for error message
Complete log: /tier4/DSC/GATK/ehlim/gatk_germline_pipeline/workflow/.snakemake/log/2020-09-09T122600.179494.snakemake.log
